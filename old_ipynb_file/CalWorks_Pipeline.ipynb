{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVMMLHHr78Ce",
        "outputId": "53ac1a0f-7a4f-4ac5-8089-0823d6dd5f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# it smells like cheetos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In a Colab cell\n",
        "%pip install -q \"pandas==2.2.2\" \"requests==2.32.4\" \\\n",
        "  \"opentelemetry-api==1.37.0\" \"opentelemetry-sdk==1.37.0\" \\\n",
        "  \"opentelemetry-proto==1.37.0\" \"opentelemetry-exporter-otlp-proto-common==1.37.0\" \\\n",
        "  \"opentelemetry-exporter-otlp-proto-http==1.37.0\"\n",
        "\n",
        "# Optional: verify no broken reqs\n",
        "!pip check\n",
        "\n",
        "# Then: Runtime â†’ Restart runtime (important)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu62FfMKlKOw",
        "outputId": "5ce4f28c-01b9-45d0-a9d8-d08dda1f5911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-exporter-otlp-proto-grpc 1.38.0 requires opentelemetry-exporter-otlp-proto-common==1.38.0, but you have opentelemetry-exporter-otlp-proto-common 1.37.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-grpc 1.38.0 requires opentelemetry-proto==1.38.0, but you have opentelemetry-proto 1.37.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-grpc 1.38.0 requires opentelemetry-sdk~=1.38.0, but you have opentelemetry-sdk 1.37.0 which is incompatible.\n",
            "langchain-community 0.4 requires requests<3.0.0,>=2.32.5, but you have requests 2.32.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mipython 7.34.0 requires jedi, which is not installed.\n",
            "opentelemetry-exporter-otlp-proto-grpc 1.38.0 has requirement opentelemetry-exporter-otlp-proto-common==1.38.0, but you have opentelemetry-exporter-otlp-proto-common 1.37.0.\n",
            "opentelemetry-exporter-otlp-proto-grpc 1.38.0 has requirement opentelemetry-proto==1.38.0, but you have opentelemetry-proto 1.37.0.\n",
            "opentelemetry-exporter-otlp-proto-grpc 1.38.0 has requirement opentelemetry-sdk~=1.38.0, but you have opentelemetry-sdk 1.37.0.\n",
            "langchain-community 0.4 has requirement requests<3.0.0,>=2.32.5, but you have requests 2.32.4.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iOlMT2yDnBe"
      },
      "source": [
        "# Parse and Chunk sectional contents from CSA and SIP documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWaTxT6w7zwG",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a023d58-c756-4a25-bfef-deb2170dab3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.12/dist-packages (1.26.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.6.1)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.4)\n",
            "Requirement already satisfied: langchain_chroma in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.1)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.23.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (34.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain_community)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.37)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (1.0.1)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.6.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.71.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Using cached opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Using cached opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain) (1.11.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
            "Using cached opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
            "Using cached opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
            "Using cached opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
            "Using cached opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Installing collected packages: requests, opentelemetry-proto, pandas, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, opentelemetry-semantic-conventions, opentelemetry-sdk\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.37.0\n",
            "    Uninstalling opentelemetry-proto-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.37.0\n",
            "    Uninstalling opentelemetry-api-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.37.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.37.0\n",
            "    Uninstalling opentelemetry-sdk-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 pandas-2.3.3 requests-2.32.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "opentelemetry",
                  "pandas",
                  "requests"
                ]
              },
              "id": "5eaec34b8a8a48208bacb1d82037e427"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install pymupdf pandas langchain openai chromadb sentence-transformers langchain_community langchain_chroma --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCHSwptU76GD",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b34f1ca1-a5fc-4064-fae9-fb2ab00f608a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12 sections in CSA-Summary-Santa-Clara-Fatal-Flaw.pdf\n",
            "Found 12 sections in CSA-Summary-Sacramento-Fatal-Flaw.pdf\n",
            "Found 12 sections in CSA-Summary-San-Francisco-Fatal-Flaw.pdf\n",
            "Found 12 sections in CSA-Summary-San-Mateo-Fatal-Flaw.pdf\n",
            "Found 12 sections in CSA Summary_Fresno_Fatal Flaw.pdf\n",
            "Found 12 sections in CSA Report_Orange.pdf\n",
            "Found 12 sections in CSA-Summary-Solano-Report.pdf\n",
            "Found 11 sections in CSA_Sonoma.pdf\n",
            "Found 12 sections in CSA_Tulare.pdf\n",
            "Found 12 sections in CSA_Santa_Cruz.pdf\n",
            "Found 12 sections in CSA_San_Luis_Obispo.pdf\n",
            "Found 12 sections in CSA_Contra_Costa.pdf\n",
            "Found 12 sections in CSA_Yolo.pdf\n",
            "Found 11 sections in CSA_Ventura.pdf\n",
            "Found 12 sections in CSA-Summary-Alameda-Fatal-Flaw.pdf\n",
            "Found 12 sections in CSA_San_Diego.pdf\n",
            "Found 12 sections in CSA Summary-SantaBarbara.pdf\n",
            "Found 12 sections in CSA-Summary-Placer.pdf\n",
            "Found 12 sections in CSA_Mariposa.pdf\n",
            "Found 12 sections in CSA Riversides.pdf\n",
            "Found 9 sections in CSA Mendocino.pdf\n",
            "Found 12 sections in CSA-Tehama.pdf\n",
            "Found 12 sections in CSA_Kern.pdf\n",
            "Found 12 sections in Cal-OAR Cal-CSA Humboldt County_APU Approved.pdf\n",
            "Found 5 sections in CalSIP_SantaClara.pdf\n",
            "Found 12 sections in CSA_Alpine.pdf\n",
            "Found 10 sections in CSA_Calaveras.pdf\n",
            "Found 5 sections in Fresno County SIP.pdf\n",
            "Found 12 sections in CSA_Report_Modoc_County.pdf\n",
            "Found 12 sections in CSA Summary_Trinity Fatal Flaw (1).pdf\n",
            "Found 12 sections in ICDSS CSA Report.pdf\n",
            "Found 12 sections in APU.Approved. CSA Report Template Yuba County - FATAL FLAW REVIEW.pdf\n",
            "Found 5 sections in Cal-SIP_Orange_Accessible.pdf\n",
            "Found 5 sections in CalSIP_FatalFlaw_Santa Barbara_12-13-23_Update_APU Approved.pdf\n",
            "Found 12 sections in CalWORKs Self-Assessment Report - Fatal Flaw Final_Madera_APU Approved.pdf\n",
            "Found 12 sections in Cal-CSA Report - Siskiyou County.pdf\n",
            "Found 11 sections in Cal-CSA Report - Kings County.pdf\n",
            "Found 11 sections in Cal-OAR Lassen CSA Report .pdf\n",
            "Found 5 sections in Cal-SIP_Sacramento v2.pdf\n",
            "Found 11 sections in Glenn County CSA Final 9.27.23 AT.pdf\n",
            "Found 12 sections in Cal-CSA Report_Del Norte County.pdf\n",
            "Found 5 sections in Solano County HSS-EE Cal-SIP 2021-2026.pdf\n",
            "Found 3 sections in San Mateo County CalWORKs System Improvement Plan.pdf\n",
            "Found 5 sections in Placer SIP Final.pdf\n",
            "Found 5 sections in CalSIP_YOLO.pdf\n",
            "Found 11 sections in Lake CSA 2-8.pdf\n",
            "Found 10 sections in CSA_Report_Colusa_County_Accessible.pdf\n",
            "Found 10 sections in Mono County Cal-CSA_Accessible.pdf\n",
            "Found 5 sections in Cal-SIP San Francisco.pdf\n",
            "Found 4 sections in Cal-SIP _Alameda__FatalFlaw1 AT.pdf\n",
            "Found 4 sections in Cal-SIP _Sonoma__FatalFlaw AT 5 (002).pdf\n",
            "Found 11 sections in CSA Report Nevada 10.3.23 Fatal Flaw AT.pdf\n",
            "Found 5 sections in Contra_Costa_Cal-SIP.pdf\n",
            "Found 5 sections in Cal-SIP Tuolumne.pdf\n",
            "Found 10 sections in San Joaquin County Cal-CSA.pdf\n",
            "Found 5 sections in cal-sip-trinity.pdf\n",
            "Found 5 sections in cal-sip-san-luis-obispo-county.pdf\n",
            "Found 5 sections in calsip-monterey.pdf\n",
            "Found 5 sections in calsip-san-bernardino.pdf\n",
            "Found 4 sections in calsip-humboldt.pdf\n",
            "Found 12 sections in cal-csa-los-angeles-report.pdf\n",
            "Found 5 sections in cal-sip-colusa-county.pdf\n",
            "Found 11 sections in cal-sip-marin-report.pdf\n",
            "Found 5 sections in cal-sip-tehama.pdf\n",
            "Found 5 sections in cal-sip-tulare-county.pdf\n",
            "Found 5 sections in cal-sip-ventura-county.pdf\n",
            "Found 5 sections in cal-sip-mendocino-county.pdf\n",
            "Found 5 sections in cal-sip-inyo-county.pdf\n",
            "Found 5 sections in cal-sip-butte-county.pdf\n",
            "Found 12 sections in CSA-Report-Napa.pdf\n",
            "Found 5 sections in cal-sip-lassen-county.pdf\n",
            "Found 10 sections in Cal-CSA-Inyo-Report-County.pdf\n",
            "Found 5 sections in calsip-san-joaquin.pdf\n",
            "Found 11 sections in csa-report-san-bernardino.pdf\n",
            "Found 11 sections in csa-report-stanislaus.pdf\n",
            "Found 5 sections in cal-sip-napa-county.pdf\n",
            "Found 5 sections in calsip-imperial.pdf\n",
            "Found 5 sections in calsip-modoc.pdf\n",
            "Found 5 sections in cal-sip-kern-county.pdf\n",
            "Found 5 sections in cal-sip-stanislaus.pdf\n",
            "Found 5 sections in cal-sip-mariposa-county.pdf\n",
            "Found 5 sections in cal-sip-madera.pdf\n",
            "Found 5 sections in cal-sip-riverside-county.pdf\n",
            "Found 5 sections in cal-sip-marin-county.pdf\n",
            "Found 5 sections in cal-sip-san-benito.pdf\n",
            "Found 4 sections in cal-sip-lake-county.pdf\n",
            "Found 5 sections in cal-sip-alpine-county.pdf\n",
            "Found 12 sections in csa-report-shasta-county.pdf\n",
            "Found 10 sections in CSA_Report_Merced_County.pdf\n",
            "Found 5 sections in cal-sip-del-norte-county.pdf\n",
            "Found 9 sections in csa-report-sanbenito.pdf\n",
            "Found 5 sections in cal-sip-el-dorado-county.pdf\n",
            "Found 4 sections in calsip-kings-county.pdf\n",
            "Found 11 sections in csa-report-sierra-county.pdf\n",
            "Found 5 sections in calsip-shasta.pdf\n",
            "Found 5 sections in calsip-siskiyou.pdf\n",
            "Found 4 sections in cal-sip-glenn-county.pdf\n",
            "Found 4 sections in cal-sip-los-angeles-county.pdf\n",
            "Found 5 sections in cal-sip-nevada-county.pdf\n",
            "Found 5 sections in cal-sip-calaveras-county.pdf\n",
            "Found 5 sections in cal-sip-mono-county.pdf\n",
            "Found 5 sections in cal-sip-sutter.pdf\n",
            "Found 12 sections in CSA-tuolumne.pdf\n",
            "Found 5 sections in calsip-sierra.pdf\n",
            "Found 12 sections in csa-report-sutter-county.pdf\n",
            "Found 5 sections in Cal-SIP Amador.pdf\n",
            "Found 11 sections in CSA-el-dorado-county.pdf\n",
            "Found 5 sections in calsip-merced.pdf\n",
            "Found 12 sections in Butte County Cal-OAR CSA_FINAL.pdf\n",
            "Found 11 sections in CSA-Report-Plumas.pdf\n",
            "Found 12 sections in Monterey County Cal-OAR CSA_FINAL.pdf\n",
            "Found 12 sections in CSA_Amador.pdf\n",
            "Found 5 sections in APU Updated Cal-SIP San Diego 020625_APU Approved.pdf\n",
            "\n",
            "931 sections to 15053 chunks\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PermissionError",
          "evalue": "[Errno 1] Operation not permitted: '/content/drive/MyDrive/CalWorks/Vector Database/Output/chunked_sip_csa_output.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-56260474.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-56260474.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_DIRECTORY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"chunked_sip_csa_output.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saved to {output_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   2437\u001b[0m             \u001b[0minf_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minf_rep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m         )\n\u001b[0;32m-> 2439\u001b[0;31m         formatter.write(\n\u001b[0m\u001b[1;32m   2440\u001b[0m             \u001b[0mexcel_writer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/formats/excel.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mneed_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             writer = ExcelWriter(\n\u001b[0m\u001b[1;32m    944\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m                 \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mengine_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[1;32m   1244\u001b[0m         )\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelWriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m             self._handles = get_handle(\n\u001b[0m\u001b[1;32m   1247\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPermissionError\u001b[0m: [Errno 1] Operation not permitted: '/content/drive/MyDrive/CalWorks/Vector Database/Output/chunked_sip_csa_output.xlsx'"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "import os\n",
        "import re\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter # Langchain update the module name as langchain_text_splitters\n",
        "\n",
        "# Configuration\n",
        "PDF_DIRECTORY = \"/content/drive/MyDrive/CalWorks/Vector Database/PDFs\"  # Set this to your PDF folder path\n",
        "OUTPUT_DIRECTORY = \"/content/drive/MyDrive/CalWorks/Vector Database/Output\" # Define output directory\n",
        "\n",
        "county_names = [\n",
        "    \"Alameda\", \"Alpine\", \"Amador\", \"Butte\", \"Calaveras\", \"Colusa\", \"Contra Costa\",\n",
        "    \"Del Norte\", \"El Dorado\", \"Fresno\", \"Glenn\", \"Humboldt\", \"Imperial\", \"Inyo\",\n",
        "    \"Kern\", \"Kings\", \"Lake\", \"Lassen\", \"Los Angeles\", \"Madera\", \"Marin\", \"Mariposa\",\n",
        "    \"Mendocino\", \"Merced\", \"Modoc\", \"Mono\", \"Monterey\", \"Napa\", \"Nevada\", \"Orange\",\n",
        "    \"Placer\", \"Plumas\", \"Riverside\", \"Sacramento\", \"San Benito\", \"San Bernardino\",\n",
        "    \"San Diego\", \"San Francisco\", \"San Joaquin\", \"San Luis Obispo\", \"San Mateo\",\n",
        "    \"Santa Barbara\", \"Santa Clara\", \"Santa Cruz\", \"Shasta\", \"Sierra\", \"Siskiyou\",\n",
        "    \"Solano\", \"Sonoma\", \"Stanislaus\", \"Sutter\", \"Tehama\", \"Trinity\", \"Tulare\",\n",
        "    \"Tuolumne\", \"Ventura\", \"Yolo\", \"Yuba\"\n",
        "]\n",
        "\n",
        "# Aliases for counties based on common filename patterns\n",
        "alias_map = {\n",
        "    \"icdss\": \"Imperial\",\n",
        "    \"lacdss\": \"Los Angeles\",\n",
        "    \"ocss\": \"Orange\",\n",
        "    \"scc\": \"Santa Clara\",\n",
        "    \"sbcs\": \"San Bernardino\",\n",
        "    # Add more aliases as needed\n",
        "}\n",
        "\n",
        "def infer_metadata_from_filename(filename):\n",
        "    # Clean and normalize\n",
        "    name_clean = filename.lower().replace(\"_\", \" \").replace(\"-\", \" \").replace(\".pdf\", \"\")\n",
        "    name_compressed = re.sub(r\"\\s+\", \"\", name_clean)\n",
        "\n",
        "    # Report type logic\n",
        "    report_type = \"Unknown\" # Initialize report_type\n",
        "    if \"sip_pr\" in name_clean:\n",
        "        report_type = \"Cal-SIP-PR\"\n",
        "    elif \"sip\" in name_clean or \"system improvement\" in name_clean:\n",
        "        report_type = \"Cal-SIP\"\n",
        "    elif (\n",
        "        \"csa\" in name_clean\n",
        "        or \"self-assessment\" in name_clean\n",
        "        or \"calworks self-assessment\" in name_clean\n",
        "        or \"county self-assessment\" in name_clean\n",
        "        or \"fatal flaw\" in name_clean\n",
        "    ):\n",
        "        report_type = \"Cal-CSA\"\n",
        "\n",
        "\n",
        "    # Try full county match\n",
        "    normalized_counties = [c.lower().replace(\" \", \"\") for c in county_names]\n",
        "    county = \"Unknown\"\n",
        "    for orig, compressed in zip(county_names, normalized_counties):\n",
        "        if compressed in name_compressed:\n",
        "            county = orig\n",
        "            break\n",
        "\n",
        "    # If not found, try alias map\n",
        "    if county == \"Unknown\":\n",
        "        for alias, full_name in alias_map.items():\n",
        "            if alias in name_compressed:\n",
        "                county = full_name\n",
        "                break\n",
        "\n",
        "    return {\n",
        "        \"file\": filename,\n",
        "        \"county\": county,\n",
        "        \"report_type\": report_type\n",
        "    }\n",
        "\n",
        "\n",
        "# A Table of Contents is needed\n",
        "def extract_sections_via_toc(pdf_path, county, report_type, toc_max_pages=5):\n",
        "    import fitz\n",
        "    import re\n",
        "\n",
        "    doc = fitz.open(pdf_path)\n",
        "    max_pages = len(doc)\n",
        "    section_entries = []\n",
        "\n",
        "    toc_lines = []\n",
        "    for i in range(min(toc_max_pages, len(doc))):\n",
        "        text = doc[i].get_text()\n",
        "        lines = text.split(\"\\n\")\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            # Match: Section headers OR named sections like \"Introduction\", \"Executive Summary\"\n",
        "            match = re.match(\n",
        "                r\"^((Section\\s+\\d+(\\.\\d+)?[.:]?\\s+.+?)|(?:Introduction|Executive Summary|Demographics))\\s+\\.{3,}\\s+(\\d{1,3})$\",\n",
        "                line,\n",
        "                re.IGNORECASE\n",
        "            )\n",
        "            if match:\n",
        "                title = match.group(1).strip()\n",
        "                page = int(match.group(4))\n",
        "                toc_lines.append((title, page))\n",
        "\n",
        "    # Construct section page ranges\n",
        "    for i, (title, start_page) in enumerate(toc_lines):\n",
        "        end_page = toc_lines[i + 1][1] - 1 if i + 1 < len(toc_lines) else max_pages\n",
        "        section_entries.append({\n",
        "            \"county\": county,\n",
        "            \"report_type\": report_type,\n",
        "            \"section_header\": title,\n",
        "            \"start_page\": start_page,\n",
        "            \"end_page\": end_page\n",
        "        })\n",
        "\n",
        "    # Extract section text\n",
        "    for section in section_entries:\n",
        "        start = max(0, section[\"start_page\"] - 1)\n",
        "        end = min(section[\"end_page\"], max_pages)\n",
        "        text = \"\".join(doc[p].get_text() for p in range(start, end))\n",
        "        section[\"text\"] = text.strip()\n",
        "\n",
        "    return section_entries\n",
        "\n",
        "\n",
        "def chunk_sections(sections, chunk_size=1000, overlap=100):\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=overlap,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
        "    )\n",
        "    chunked = []\n",
        "    for sec in sections:\n",
        "        if not sec[\"text\"].strip():\n",
        "            continue\n",
        "        splits = splitter.split_text(sec[\"text\"])\n",
        "        for i, chunk in enumerate(splits):\n",
        "            chunked.append({\n",
        "                \"county\": sec[\"county\"],\n",
        "                \"report_type\": sec[\"report_type\"],\n",
        "                \"section\": sec[\"section_header\"],\n",
        "                \"page\": sec[\"start_page\"],\n",
        "                \"chunk_id\": f\"{sec['section_header']}_chunk{i}\",\n",
        "                \"text\": chunk\n",
        "            })\n",
        "    return chunked\n",
        "\n",
        "def main():\n",
        "    # Create output directory if it doesn't exist\n",
        "    if not os.path.exists(OUTPUT_DIRECTORY):\n",
        "        os.makedirs(OUTPUT_DIRECTORY)\n",
        "\n",
        "    pdf_files = [f for f in os.listdir(PDF_DIRECTORY) if f.endswith(\".pdf\")]\n",
        "    all_sections = []\n",
        "\n",
        "    for file in pdf_files:\n",
        "        meta = infer_metadata_from_filename(file)\n",
        "        if meta[\"county\"] == \"Unknown\" or meta[\"report_type\"] == \"Unknown\":\n",
        "            print(f\"Skipping: {file} (missing county or type)\")\n",
        "            continue\n",
        "        try:\n",
        "            path = os.path.join(PDF_DIRECTORY, file)\n",
        "            sections = extract_sections_via_toc(path, meta[\"county\"], meta[\"report_type\"])\n",
        "\n",
        "            if len(sections) == 0:\n",
        "                print(f\"No TOC sections found for: {file}\")\n",
        "            else:\n",
        "                print(f\"Found {len(sections)} sections in {file}\")\n",
        "                all_sections.extend(sections)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file}: {e}\")\n",
        "\n",
        "    chunks = chunk_sections(all_sections)\n",
        "    print(f\"\\n{len(all_sections)} sections to {len(chunks)} chunks\")\n",
        "\n",
        "    output_path = os.path.join(OUTPUT_DIRECTORY, \"chunked_sip_csa_output.xlsx\")\n",
        "    df = pd.DataFrame(chunks)\n",
        "    df.to_excel(output_path, index=False)\n",
        "    print(f\"Saved to {output_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqNuI44fEJ7Z"
      },
      "source": [
        "# ChromaDb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1zqKdrxxOUa"
      },
      "source": [
        "# Other Free and Efficient Embedding Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNqgRkqWEYrN",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89886789-7961-43c7-8781-ee4fe62eca64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Chroma collection 'sip_csa_chunks' at '/content/drive/MyDrive/[Huggingface Embedding]'...\n",
            "âœ… Chroma collection 'sip_csa_chunks' created and populated.\n",
            "Total documents added to collection: 15053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3887896794.py:68: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  vectorstore.persist()\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings  # Use HuggingFaceEmbeddings\n",
        "from langchain_core.documents import Document  # Langchain Document storage and retrieval\n",
        "from langchain_community.vectorstores import Chroma # Use langchain_community.vectorstores\n",
        "\n",
        "# Configuration\n",
        "XLSX_PATH   = \"/content/drive/MyDrive/CalWorks/Vector Database/Output/chunked_sip_csa_output.xlsx\"\n",
        "PERSIST_DIR = \"/content/drive/MyDrive/CalWorks/Vector Database/Output/chroma_sip_csa_db[Huggingface Embedding]\"\n",
        "COLLECTION  = \"sip_csa_chunks\"\n",
        "\n",
        "# Normalize Text\n",
        "def normalize_text(text: str) -> str:\n",
        "    text = text.strip()\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    text = re.sub(r\"â€|â€“|â€”\", \"-\", text)\n",
        "    text = re.sub(r\"â€œ|â€|\\\"|''\", '\"', text)\n",
        "    text = re.sub(r\"â€™|â€˜|`\", \"'\", text)\n",
        "    return text\n",
        "\n",
        "# Load Excel Data\n",
        "df = pd.read_excel(XLSX_PATH).dropna(subset=[\"text\"])\n",
        "df[\"chunk_id\"] = df.apply(\n",
        "    lambda row: f\"{row['county'].replace(' ', '')}_{row['report_type'].replace('-', '')}_{row['section'].replace(':', '').replace('.', '').replace(' ', '')}_chunk{row.name}\",\n",
        "    axis=1\n",
        ")\n",
        "df[\"text\"] = df[\"text\"].apply(normalize_text)\n",
        "df[\"section\"] = df[\"section\"].astype(str).apply(normalize_text)\n",
        "\n",
        "\n",
        "# Use HuggingFace embeddings\n",
        "embedding_func = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Prepare Documents for LangChain's Chroma.from_documents\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=row[\"text\"],\n",
        "        metadata={\n",
        "            \"county\": row[\"county\"],\n",
        "            \"report_type\": row[\"report_type\"],\n",
        "            \"section\": row[\"section\"],\n",
        "            \"page\": row[\"page\"],\n",
        "            \"chunk_id\": row[\"chunk_id\"] # Include chunk_id in metadata\n",
        "        }\n",
        "    )\n",
        "    for _, row in df.iterrows()\n",
        "]\n",
        "\n",
        "# Clear the persistence directory if it exists to avoid conflicts\n",
        "if os.path.exists(PERSIST_DIR):\n",
        "    print(f\"Clearing existing Chroma directory: {PERSIST_DIR}\")\n",
        "    shutil.rmtree(PERSIST_DIR)\n",
        "\n",
        "\n",
        "print(f\"Creating Chroma collection '{COLLECTION}' at '{PERSIST_DIR}'...\")\n",
        "\n",
        "# Create and populate the Chroma collection\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embedding_func,\n",
        "    collection_name=COLLECTION,\n",
        "    persist_directory=PERSIST_DIR\n",
        ")\n",
        "vectorstore.persist()\n",
        "\n",
        "print(f\"âœ… Chroma collection '{COLLECTION}' created and populated.\")\n",
        "\n",
        "# Optional: Verify document count\n",
        "print(f\"Total documents added to collection: {vectorstore._collection.count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkmggEfh9wDN",
        "outputId": "0a8dd075-5198-4bd1-860c-942ba3af27ea",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Query Result:\n",
            "Result 1: authorization to client (including vouchers, payment, tracking, etc.). Full-time childcare authorization is provided through the Immediate and Continuous Eligibility process. Once a family is referred to WTW, if the family has a child who is under the age of 13, or a child of any age who has a disab...\n",
            "---\n",
            "Result 2: in the forms prior to attending their orientation. Upon receipt, CWES Engagement Unit staff approve child care for a 12 month period from the start date listed on the child care packet. Child care can be provided as early as the start date of the client's Cash Aid benefits. 80 For clients already en...\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# Optional: Run test query\n",
        "try:\n",
        "    # result = collection.query(query_texts=[\"childcare support\"], n_results=2)\n",
        "    # collection has been decreapted by cromadb, I changed to langchain api vectorstore\n",
        "    results = vectorstore.similarity_search(\"childcare support\", k=2)\n",
        "    print(\"\\nSample Query Result:\")\n",
        "    for i, r in enumerate(results):\n",
        "        print(f\"Result {i+1}: {r.page_content[:300]}...\\n---\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during sample query: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaY3881h-QrF",
        "outputId": "aa6d5cf4-e2a8-4fb4-e81d-06f16898a967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Document 1 ---\n",
            "Metadata: {'section': 'Section 4. Initial Engagement Analysis', 'county': 'San Mateo', 'report_type': 'Cal-CSA', 'chunk_id': 'SanMateo_CalCSA_Section4InitialEngagementAnalysis_chunk804', 'page': 32}\n",
            "Content: authorization to client (including vouchers, payment, tracking, etc.). Full-time childcare authorization is provided through the Immediate and Continuous Eligibility process. Once a family is referred to WTW, if the family has a child who is under the age of 13, or a child of any age who has a disab...\n",
            "\n",
            "--- Document 2 ---\n",
            "Metadata: {'section': 'Section 4. Initial Engagement Analysis', 'county': 'Santa Clara', 'chunk_id': 'SantaClara_CalCSA_Section4InitialEngagementAnalysis_chunk217', 'report_type': 'Cal-CSA', 'page': 72}\n",
            "Content: in the forms prior to attending their orientation. Upon receipt, CWES Engagement Unit staff approve child care for a 12 month period from the start date listed on the child care packet. Child care can be provided as early as the start date of the client's Cash Aid benefits. 80 For clients already en...\n",
            "\n",
            "--- Document 3 ---\n",
            "Metadata: {'page': 51, 'report_type': 'Cal-CSA', 'county': 'Trinity', 'section': 'Section 4. Initial Engagement Analysis', 'chunk_id': 'Trinity_CalCSA_Section4InitialEngagementAnalysis_chunk6271'}\n",
            "Content: time, and Trust-line care. Families engaged in any approved activity and where childcare needs are identified have access to Stage One childcare through the aforementioned service provider. Authorization is sent via a referral to HRN. This 60 agency is responsible for recruitment, training and provi...\n"
          ]
        }
      ],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Setup\n",
        "PERSIST_DIR = \"/content/drive/MyDrive/CalWorks/Vector Database/Output/chroma_sip_csa_db[Huggingface Embedding]\"\n",
        "COLLECTION  = \"sip_csa_chunks\"\n",
        "\n",
        "embedding_func = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Load vectorstore\n",
        "vectorstore = Chroma(\n",
        "    collection_name=COLLECTION,\n",
        "    persist_directory=PERSIST_DIR,\n",
        "    embedding_function=embedding_func\n",
        ")\n",
        "\n",
        "# Create retriever\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "\n",
        "# Run a query\n",
        "# use .invoke\n",
        "docs = retriever.invoke(\"childcare support\")\n",
        "for i, doc in enumerate(docs):\n",
        "    print(f\"\\n--- Document {i+1} ---\")\n",
        "    print(f\"Metadata: {doc.metadata}\")\n",
        "    print(f\"Content: {doc.page_content[:300]}...\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "PERSIST_DIR = \"/content/drive/MyDrive/CalWorks/Vector Database/Output/chroma_sip_csa_db[Huggingface Embedding]\"\n",
        "\n",
        "client = chromadb.PersistentClient(\n",
        "    path=PERSIST_DIR,\n",
        "    settings=Settings(anonymized_telemetry=True)\n",
        ")\n"
      ],
      "metadata": {
        "id": "MDfpd6hNM4hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"/content/drive/MyDrive/CalWorks/Vector Database/Output/chroma_sip_csa_db[Huggingface Embedding]\"))  # çœ‹çœ‹é‡Œé¢æœ‰æ²¡æœ‰ metadata.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTrYy-RW-msQ",
        "outputId": "af3436a7-1f4e-4196-abb3-6b8555dd785a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['chroma.sqlite3', 'af86c337-2244-45e6-9eab-a2770ff68183']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collections = client.list_collections()\n",
        "\n",
        "print(\"ðŸ“¦ Collections and document counts:\")\n",
        "for col in collections:\n",
        "    # Get the collection object\n",
        "    c = client.get_collection(col.name)\n",
        "    print(f\"- {col.name}: {c.count()} documents\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FTTAFqGnJT9",
        "outputId": "c060dcf2-a801-464a-d56b-d1a7747e9ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¦ Collections and document counts:\n",
            "- sip_csa_chunks: 15053 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7kCbb87Yn-bM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}